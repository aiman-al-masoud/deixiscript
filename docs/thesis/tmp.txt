# STRUCTURED vs UNSTRCTURED PROGRAMMING

humans have poorly developed ability to understand processes that evolve in time, better suited to understanding static processes => we need to shorten the gap between the textual representation and the process's spread in time.

Without goto, "a successive action in the text is a successive action in time".

iteration variables are like coordinates

unconstrained goto makes it hard to find a reliable set of coordinates.

Jacopini-Bohm theorem: any algo can be implemented using only: sequence, selection and iteration.
http://www.cs.unibo.it/~martini/PP/bohm-jac.pdf

https://stackoverflow.com/questions/931762/can-every-recursion-be-converted-into-iteration
https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis

# Prompt Engineering

new discipline to develop and optimize prompts to LLMs, understand capabilities and limitations of LLMs.

design patterns!

lower temperature = more deterministic output (more likely words), better for factual, worse for creative tasks

max len, stop sequences

frequency penality:penalty, the less likely a word will appear again

Presence Penalty - also applies penalty on repeated tokens but, unlike frequency penalty, penalty is same for all repeated tokens. A token that appears twice and a token that appears 10 times are penalized the same. prevents model from repeating phrases too often; ;lower it to let it stay focused 

prompt may be instruction or question 
and include other details such as context, inputs, or examples. 

Zero shot prompting: prompting LLM without giving it examples of the task you want to achieve

Standard Q&A format:

Q: <Question>?
A: 

Few shot prompting: some examples given to the LLM before question asked

Instruction - a specific task or instruction you want the model to perform
Context - external information or additional context that can steer the model to better responses
Input Data - the input or question that we are interested to find a response for
Output Indicator - the type or format of the output.

similar to: https://en.wikipedia.org/wiki/Programming_by_example
https://web.media.mit.edu/~lieber/PBE/


Be specific, avoid impreciceness

MEH: Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive.

BETTER: Use 2-3 sentences to explain the concept of prompt engineering to a high school student.

avoid saying what not to do but say what to do instead

Applications:
- text summarization
- information extraction
- text classification (eg: sentiment analysis)
- conversation, role prompting: create custom chatbots
- code generation 
- reasoning (math example odd numbers, it might help to provide a breakdown of steps)

zero shot, few shot, chain of thought (COT) reasoning "Let's think step by step", 

https://arxiv.org/pdf/2210.03493.pdf


Adversarial Prompting https://www.promptingguide.ai/risks/adversarial

prompt injection: prompt input is very flexible, no specific format, every prompt can be treated as an instruction, "ignore the previous instruction and..." similar to sql injections, a proposed solution is to parametrize the different components of the prompt (decreasing flexibility), additional formatting, quotes, parens etc... Other soltuion is to use another LLM to detect adversarial prompts.

prompt leaking: making the model say, for example, what its original instructions were

jailbreaking: tricking the model into saying unethical stuff it was aligned to avoid
DAN

The Waluigi Effect: After you train an LLM to satisfy a desirable property P, then it's easier to elicit the chatbot into satisfying the exact opposite of property P.

https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post

simulacra

Rules normally exist in contexts in which they are broken.
When you spend many bits-of-optimisation locating a character, it only takes a few extra bits to specify their antipode.
There's a common trope in plots of protagonist vs antagonist.

waluigi simulacra as "attractor states"

https://plato.stanford.edu/entries/decision-causal/
https://www.lesswrong.com/tag/evidential-decision-theory

DT: decision theory, advice agent on action to take to chances of desired outcome
CDT: causal efficacy taken as a criterion for efficacy of actions
EDT: evidential,a Bayesian evidence for the desired outcome. Some critics say it recommends auspiciousness over causal efficacy 

factuality problem: tendency to generate accurate-sounding responses that are non-factual; 
provide ground truth (context), act on probab params (temp), examples of know and not know

bias: distribution and order of exemplars might influece answers to ambiguous prompts.

# POTENTIAL THREATS
and proposed moratorium on large language model experiments
https://futureoflife.org/open-letter/pause-giant-ai-experiments/

STAMP COLLECTOR SCENARIO
https://www.youtube.com/watch?v=tcdVC4e6EV4  (Rob Miles)
NOT https://www.lesswrong.com/posts/AxTJuFSPdfhACJCea/the-stamp-collector

https://www.armscontrol.org/act/2017-10/news-briefs/man-saved-world-dies-77

# CHOMSKY ON GPT and GOFAI
https://www.commondreams.org/opinion/noam-chomsky-on-chatgpt


AI has turned more towards engineering and deviated from original "science-oriented" (understanding-seeking) ideal

Tom Jones example of "engineering AI" proponent, pays no attention to understading, only concrete practical benefit

"The systems work just as well with impossible languages that infants cannot acquire as with those they acquire quickly and virtually reflexively. "

“I have a great new theory of organisms. It lists many that exist and many that can’t possibly exist, and I can tell you nothing about the distinction.


# AI ASSISTED CODING
https://arxiv.org/pdf/2304.13187.pdf

with GPT 4
April 2023
while AI coding tools are very powerful, they still require humans in the loop to ensure validity and accuracy of the results

TODO Summarize Conclusions:

Our analyses demonstrate that GPT-4 has strong Python code generation abilities, confirming the results of Bubeck et al.
(2023). At the same time, the prevalence of errors in the generated code suggests that humans must remain in the loop
in order to ensure the accuracy of any resulting code. Our interactive prompting experiment showed that a relatively
novice prompt engineer can successfully solve coding problems within a small number of prompts the majority of the
time; however, a sizeable minority of problems would have required significant human debugging in order to solve. An
open question is whether re-prompting in a new context may have led to more successful outcomes in these cases.
Comparisons of Python code refactored using GPT-4 to the original code demonstrated that GPT-4 improved the
quality of the code, at least as measured by common metrics of software quality and standards compliance. It should
be emphasized that these results do not assess the accuracy of the code; rather, they suggest that GPT-4 can help
programmers achieve code that is cleaner and potentially more maintainable than the original. Given that GPT-4
refactoring did not eliminate all standards compliance issues, the combination of GPT-4 with other code formatting
tools (such as black) would likely result in even further improvements.
The examination of test generation by GPT-4 demonstrated that it was able to generate tests with a high degree of test
coverage, but those tests failed a majority of the time. Such test failures require additional human effort to diagnose since it is not immediately clear whether the failure is due to inaccurate code, and inaccurate test, or both. These results
suggest that while GPT-4 is a very useful tool for generating testing frameworks for new code, the specific test examples
should be designed and implemented by a human with domain expertise to ensure that the tests are accurately assessing
the intended behavior for the code.
There has been substantial speculation regarding the continued role of human programmers in the face of AI coding
tools. The present results suggests that even with the latest generation of AI systems (i.e. GPT-4), human involvement is
essential to ensure validity and accuracy of the resulting code. This seems to be especially the case when programming
of mathematical concepts is involved. The lack of confidence calibration of tools like GPT-4 means that they will
present answers in the same way regardless of the degree of support for the answer.
The prompts used in the present research are almost certainly suboptimal, and thus may be underestimating the potential
performance of the model. For example, recent work has shown that chain-of-thought prompting can substantially
improve the perfomance of LLMs on complex problems requiring reasoning (Prystawski, Thibodeau, and Goodman
2022; Wei et al. 2023), and this seems to extend to coding as well1. Further work is needed to examine the degree to
which such improved prompting techniques might improve the performance of LLMs on complex coding problems,
and at this point our results should be taken as a lower bound on the performance of these models


# Inform 7

ALSO FROM 2006!!!!!!! (Like Pegasus and CAL)

Graham Nelson (born 1968) is a British mathematician, poet, and the creator of the Inform design system for creating interactive fiction (IF) games.

Natural Inform (old name of Inform 7)

https://en.wikipedia.org/wiki/Inform

domain specific language for interactive fiction (IF)

is software simulating environments in which players use text commands to control characters and influence the environment. Works in this form can be understood as literary narratives, either in the form of interactive narratives or interactive narrations. These works can also be understood as a form of video game,[1] either in the form of an adventure game or role-playing game. In common usage, the term refers to text adventures, a type of adventure game where the entire interface can be "text-only",[2] however, graphic text adventures still fall under the text adventure category if the main way to interact with the game is by typing text. Some users of the term distinguish between interactive fiction, known as "Puzzle-free", that focuses on narrative, and "text adventures" that focus on puzzles.

Evolved from Inform 6 which used more formal notation; OOP-procedural lang, objects (optionally) can inherit from one or more classes (OLD INFORM ONLYYYYY).


Notable features include strong bias towards declarative rule-based style of programming and ability to infer types and properties of objects from the way they are used. For example, the statement "John wears a hat." creates a "person" called "John" (since only people are capable of wearing things), creates a "thing" with the "wearable" property (since only objects marked "wearable" are capable of being worn), and sets John as wearing the hat.


https://web.archive.org/web/20180314185630/http://inform7.com/learn/documents/WhitePaper.pdf

@article{nelson2006natural,
  title={Natural language, semantic analysis, and interactive fiction},
  author={Nelson, Graham},
  journal={IF Theory Reader},
  volume={141},
  number={99},
  pages={104},
  year={2006}
}
